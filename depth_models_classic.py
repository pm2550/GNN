#!/usr/bin/env python3
"""
åŸºäºç»å…¸æ¶æ„çš„EdgeTPUæ·±åº¦ä¼°è®¡æ¨¡å‹
1. MobileNetV2 + æ·±åº¦ä¼°è®¡å¤´ (ç±»ä¼¼FastDepth)
2. åŸºäºå·²å‘è¡¨è®ºæ–‡çš„æˆç†Ÿæ¶æ„
"""

import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
from tensorflow.keras.applications import MobileNetV2
import numpy as np
import subprocess
import os

class FastDepthEdgeTPU:
    """
    åŸºäºFastDepthè®ºæ–‡çš„EdgeTPUä¼˜åŒ–ç‰ˆæœ¬
    å‚è€ƒ: FastDepth: Fast Monocular Depth Estimation on Embedded Systems (ICRA 2019)
    """
    
    def __init__(self, input_height=480, input_width=640):
        self.input_height = input_height
        self.input_width = input_width
        
    def build_fastdepth_model(self):
        """æ„å»ºåŸºäºMobileNetV2çš„FastDepthæ¨¡å‹"""
        
        # è¾“å…¥
        input_tensor = Input(shape=(self.input_height, self.input_width, 3), name="rgb_input")
        
        # ä½¿ç”¨é¢„è®­ç»ƒçš„MobileNetV2ä½œä¸ºencoder (å»æ‰é¡¶å±‚)
        backbone = MobileNetV2(
            input_tensor=input_tensor,
            weights='imagenet',
            include_top=False,
            alpha=1.0  # ä½¿ç”¨å®Œæ•´ç‰ˆæœ¬ä»¥è·å¾—æœ€ä½³ç‰¹å¾
        )
        
        # æå–å¤šå°ºåº¦ç‰¹å¾ (FastDepthè®ºæ–‡ä¸­çš„skip connections)
        # MobileNetV2çš„å…³é”®å±‚
        skip1 = backbone.get_layer('block_1_expand_relu').output    # 112x112
        skip2 = backbone.get_layer('block_3_expand_relu').output    # 56x56  
        skip3 = backbone.get_layer('block_6_expand_relu').output    # 28x28
        skip4 = backbone.get_layer('block_13_expand_relu').output   # 14x14
        skip5 = backbone.output                                     # 7x7
        
        # FastDepthçš„ä¸Šé‡‡æ ·è§£ç å™¨
        # ç¬¬ä¸€å±‚ä¸Šé‡‡æ ·
        x = UpSampling2D(size=(2, 2), interpolation='nearest', name='upsample_1')(skip5)
        x = Concatenate(name='concat_1')([x, skip4])
        x = Conv2D(512, 3, padding='same', activation='relu', name='decode_conv_1')(x)
        
        # ç¬¬äºŒå±‚ä¸Šé‡‡æ ·  
        x = UpSampling2D(size=(2, 2), interpolation='nearest', name='upsample_2')(x)
        x = Concatenate(name='concat_2')([x, skip3])
        x = Conv2D(256, 3, padding='same', activation='relu', name='decode_conv_2')(x)
        
        # ç¬¬ä¸‰å±‚ä¸Šé‡‡æ ·
        x = UpSampling2D(size=(2, 2), interpolation='nearest', name='upsample_3')(x)
        x = Concatenate(name='concat_3')([x, skip2])
        x = Conv2D(128, 3, padding='same', activation='relu', name='decode_conv_3')(x)
        
        # ç¬¬å››å±‚ä¸Šé‡‡æ ·
        x = UpSampling2D(size=(2, 2), interpolation='nearest', name='upsample_4')(x)
        x = Concatenate(name='concat_4')([x, skip1])
        x = Conv2D(64, 3, padding='same', activation='relu', name='decode_conv_4')(x)
        
        # æœ€ç»ˆä¸Šé‡‡æ ·åˆ°åŸå§‹åˆ†è¾¨ç‡
        x = UpSampling2D(size=(2, 2), interpolation='bilinear', name='upsample_final')(x)
        
        # æ·±åº¦è¾“å‡ºå±‚
        depth_output = Conv2D(1, 3, padding='same', activation='sigmoid', name='depth_output')(x)
        
        model = Model(inputs=input_tensor, outputs=depth_output, name='FastDepth_EdgeTPU')
        return model

class MobileNetV2StereoDepth:
    """
    åŸºäºMobileNetV2çš„ç«‹ä½“æ·±åº¦ä¼°è®¡æ¨¡å‹
    å‚è€ƒç»å…¸çš„ç«‹ä½“åŒ¹é…æ¶æ„
    """
    
    def __init__(self, input_height=480, input_width=640, max_disparity=64):
        self.input_height = input_height
        self.input_width = input_width
        self.max_disparity = max_disparity
        
    def create_shared_encoder(self):
        """åˆ›å»ºå…±äº«çš„MobileNetV2ç¼–ç å™¨"""
        
        input_tensor = Input(shape=(self.input_height, self.input_width, 3))
        
        # ä½¿ç”¨MobileNetV2ä½œä¸ºç‰¹å¾æå–å™¨
        backbone = MobileNetV2(
            input_tensor=input_tensor,
            weights='imagenet',
            include_top=False,
            alpha=0.75  # ä½¿ç”¨0.75å€å®½åº¦ä»¥å‡å°‘è®¡ç®—é‡
        )
        
        # é€‰æ‹©åˆé€‚çš„ç‰¹å¾å±‚ (1/4åˆ†è¾¨ç‡)
        features = backbone.get_layer('block_6_expand_relu').output  # 60x80x144
        
        return Model(inputs=input_tensor, outputs=features, name='stereo_encoder')
    
    def correlation_layer(self, left_features, right_features):
        """è®¡ç®—å·¦å³ç‰¹å¾çš„ç›¸å…³æ€§ - ç®€åŒ–ç‰ˆæœ¬"""
        
        batch_size = tf.shape(left_features)[0]
        height = tf.shape(left_features)[1] 
        width = tf.shape(left_features)[2]
        channels = tf.shape(left_features)[3]
        
        # ç®€åŒ–çš„ç›¸å…³æ€§è®¡ç®—
        max_disp = self.max_disparity // 4  # é€‚åº”feature mapåˆ†è¾¨ç‡
        cost_volume = []
        
        for d in range(0, max_disp, 2):  # æ¯éš”2ä¸ªåƒç´ è®¡ç®—ä¸€æ¬¡
            if d == 0:
                shifted_right = right_features
            else:
                # å‘å·¦å¹³ç§»
                padding = tf.zeros([batch_size, height, d, channels])
                shifted_right = tf.concat([
                    right_features[:, :, d:, :], 
                    padding
                ], axis=2)
            
            # è®¡ç®—ç»å¯¹å·®å€¼
            correlation = tf.reduce_mean(tf.abs(left_features - shifted_right), axis=-1, keepdims=True)
            cost_volume.append(correlation)
        
        return tf.concat(cost_volume, axis=-1)
    
    def build_stereo_model(self):
        """æ„å»ºå®Œæ•´çš„ç«‹ä½“æ·±åº¦ä¼°è®¡æ¨¡å‹"""
        
        # è¾“å…¥
        left_input = Input(shape=(self.input_height, self.input_width, 3), name='left_image')
        right_input = Input(shape=(self.input_height, self.input_width, 3), name='right_image')
        
        # å…±äº«ç¼–ç å™¨
        encoder = self.create_shared_encoder()
        
        left_features = encoder(left_input)
        right_features = encoder(right_input)
        
        # è®¡ç®—cost volume
        cost_volume = self.correlation_layer(left_features, right_features)
        
        # æ·±åº¦å›å½’ç½‘ç»œ
        x = Conv2D(64, 3, padding='same', activation='relu', name='regress_conv1')(cost_volume)
        x = Conv2D(32, 3, padding='same', activation='relu', name='regress_conv2')(x)
        x = Conv2D(16, 3, padding='same', activation='relu', name='regress_conv3')(x)
        
        # æ·±åº¦é¢„æµ‹
        depth_low = Conv2D(1, 3, padding='same', activation='sigmoid', name='depth_low')(x)
        
        # ä¸Šé‡‡æ ·åˆ°åŸå§‹åˆ†è¾¨ç‡
        depth_output = UpSampling2D(size=(4, 4), interpolation='bilinear', name='depth_final')(depth_low)
        
        model = Model(
            inputs=[left_input, right_input], 
            outputs=depth_output, 
            name='MobileNetV2_StereoDepth'
        )
        
        return model

class MiDaSMobileNet:
    """
    åŸºäºMiDaSæ€æƒ³çš„MobileNetæ·±åº¦ä¼°è®¡æ¨¡å‹
    å‚è€ƒ: Towards Robust Monocular Depth Estimation (MiDaSè®ºæ–‡)
    """
    
    def __init__(self, input_height=480, input_width=640):
        self.input_height = input_height
        self.input_width = input_width
        
    def build_midas_mobilenet(self):
        """æ„å»ºMiDaSé£æ ¼çš„MobileNetæ¨¡å‹"""
        
        input_tensor = Input(shape=(self.input_height, self.input_width, 3), name='image_input')
        
        # MobileNetV2 backbone
        backbone = MobileNetV2(
            input_tensor=input_tensor,
            weights='imagenet',
            include_top=False,
            alpha=1.0
        )
        
        # å¤šå°ºåº¦ç‰¹å¾èåˆ (MiDaSçš„æ ¸å¿ƒæ€æƒ³)
        feature_16 = backbone.get_layer('block_1_expand_relu').output   # 1/2 - 128x128
        feature_8 = backbone.get_layer('block_3_expand_relu').output    # 1/4 - 64x64
        feature_4 = backbone.get_layer('block_6_expand_relu').output    # 1/8 - 32x32
        feature_2 = backbone.get_layer('block_13_expand_relu').output   # 1/16 - 16x16
        feature_1 = backbone.output                                     # 1/32 - 8x8
        
        # Feature Fusion Module (ç±»ä¼¼MiDaS)
        def feature_fusion_block(features, target_size, name_prefix):
            """ç‰¹å¾èåˆå— - ä½¿ç”¨å›ºå®šçš„ç¼©æ”¾ç­–ç•¥"""
            target_h, target_w = target_size
            
            # æ ¹æ®å·²çŸ¥çš„ç‰¹å¾å°ºå¯¸è¿›è¡Œè°ƒæ•´
            # feature_16: 128x128 -> 32x32 (éœ€è¦1/4ä¸‹é‡‡æ ·)
            # feature_8:  64x64  -> 32x32 (éœ€è¦1/2ä¸‹é‡‡æ ·) 
            # feature_4:  32x32  -> 32x32 (ä¸éœ€è¦è°ƒæ•´)
            # feature_2:  16x16  -> 32x32 (éœ€è¦2xä¸Šé‡‡æ ·)
            # feature_1:  8x8    -> 32x32 (éœ€è¦4xä¸Šé‡‡æ ·)
            
            if 'fuse_16' in name_prefix:
                # 128x128 -> 32x32
                resized = AveragePooling2D(pool_size=(4, 4), strides=(4, 4), 
                                         name=f'{name_prefix}_downsample')(features)
            elif 'fuse_8' in name_prefix:
                # 64x64 -> 32x32  
                resized = AveragePooling2D(pool_size=(2, 2), strides=(2, 2),
                                         name=f'{name_prefix}_downsample')(features)
            elif 'fuse_4' in name_prefix:
                # 32x32 -> 32x32 (already correct size)
                resized = features
            elif 'fuse_2' in name_prefix:
                # 16x16 -> 32x32
                resized = UpSampling2D(size=(2, 2), interpolation='bilinear',
                                     name=f'{name_prefix}_upsample')(features)
            elif 'fuse_1' in name_prefix:
                # 8x8 -> 32x32
                resized = UpSampling2D(size=(4, 4), interpolation='bilinear',
                                     name=f'{name_prefix}_upsample')(features)
            else:
                resized = features
            
            # é€šé“è°ƒæ•´åˆ°256
            adjusted = Conv2D(256, 1, padding='same', name=f'{name_prefix}_adjust')(resized)
            return adjusted
        
        target_size = [self.input_height // 8, self.input_width // 8]  # 1/8åˆ†è¾¨ç‡ä½œä¸ºèåˆç›®æ ‡ (32x32)
        
        # å°†æ‰€æœ‰ç‰¹å¾è°ƒæ•´åˆ°ç›¸åŒå°ºå¯¸ (32x32x256)
        fused_1 = feature_fusion_block(feature_1, target_size, 'fuse_1')     # 8x8 -> 32x32
        fused_2 = feature_fusion_block(feature_2, target_size, 'fuse_2')     # 16x16 -> 32x32
        fused_4 = feature_fusion_block(feature_4, target_size, 'fuse_4')     # 32x32 -> 32x32 (already correct size)
        fused_8 = feature_fusion_block(feature_8, target_size, 'fuse_8')     # 64x64 -> 32x32
        fused_16 = feature_fusion_block(feature_16, target_size, 'fuse_16')  # 128x128 -> 32x32
        
        # ç‰¹å¾èåˆ - ç°åœ¨æ‰€æœ‰ç‰¹å¾éƒ½æ˜¯32x32x256
        fused_features = Add(name='feature_fusion')([fused_1, fused_2, fused_4, fused_8, fused_16])
        fused_features = ReLU(name='fusion_relu')(fused_features)
        
        # æ·±åº¦è§£ç å™¨
        x = Conv2D(128, 3, padding='same', activation='relu', name='decode_1')(fused_features)
        x = UpSampling2D(size=(2, 2), interpolation='bilinear', name='up_1')(x)
        
        x = Conv2D(64, 3, padding='same', activation='relu', name='decode_2')(x)
        x = UpSampling2D(size=(2, 2), interpolation='bilinear', name='up_2')(x)
        
        x = Conv2D(32, 3, padding='same', activation='relu', name='decode_3')(x)
        x = UpSampling2D(size=(2, 2), interpolation='bilinear', name='up_3')(x)
        
        # æœ€ç»ˆæ·±åº¦è¾“å‡º
        depth_output = Conv2D(1, 3, padding='same', activation='sigmoid', name='depth_final')(x)
        
        model = Model(inputs=input_tensor, outputs=depth_output, name='MiDaS_MobileNet')
        return model

def optimize_for_edgetpu(model, model_name):
    """ä¸ºEdgeTPUä¼˜åŒ–æ¨¡å‹"""
    
    print(f"ğŸ”§ ä¸ºEdgeTPUä¼˜åŒ– {model_name}...")
    
    # é‡åŒ–æ„ŸçŸ¥è®­ç»ƒé…ç½®
    import tensorflow_model_optimization as tfmot
    
    # å®šä¹‰é‡åŒ–é…ç½® - é’ˆå¯¹EdgeTPUä¼˜åŒ–
    def apply_quantization(layer):
        if isinstance(layer, tf.keras.layers.Conv2D):
            return tfmot.quantization.keras.quantize_annotate_layer(layer)
        if isinstance(layer, tf.keras.layers.DepthwiseConv2D):
            return tfmot.quantization.keras.quantize_annotate_layer(layer)
        return layer
    
    # åº”ç”¨é‡åŒ–æ³¨è§£
    annotated_model = tf.keras.models.clone_model(
        model,
        clone_function=apply_quantization,
    )
    
    # é‡åŒ–æ¨¡å‹
    quantized_model = tfmot.quantization.keras.quantize_apply(annotated_model)
    
    return quantized_model

def convert_to_tflite(model, model_name):
    """æ­¥éª¤1: è½¬æ¢ä¸ºTensorFlow Lite (åŸºç¡€è½¬æ¢)"""
    
    print(f"ğŸ“¦ æ­¥éª¤1: è½¬æ¢ {model_name} ä¸ºTFLite...")
    
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    
    # åŸºç¡€ä¼˜åŒ–ï¼Œä¸é‡åŒ–
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    
    # è½¬æ¢
    tflite_model = converter.convert()
    
    # ä¿å­˜åŸºç¡€TFLiteæ¨¡å‹
    output_path = f"{model_name.lower()}.tflite"
    with open(output_path, 'wb') as f:
        f.write(tflite_model)
    
    print(f"âœ… TFLiteæ¨¡å‹å·²ä¿å­˜: {output_path}")
    print(f"   æ¨¡å‹å¤§å°: {len(tflite_model) / (1024*1024):.2f} MB")
    return output_path

def quantize_keras_to_tflite(keras_model, model_name, representative_data_gen):
    """æ­¥éª¤2: ä»Kerasæ¨¡å‹ç›´æ¥é‡åŒ–ä¸ºINT8 TFLite"""
    
    print(f"âš™ï¸  æ­¥éª¤2: é‡åŒ– {model_name} ä¸ºINT8...")
    
    # ç”Ÿæˆé‡åŒ–ç‰ˆæœ¬æ–‡ä»¶å
    quantized_path = f"{model_name.lower()}_quantized.tflite"
    
    try:
        print(f"ğŸ”„ æ­£åœ¨è¿›è¡ŒINT8é‡åŒ–...")
        
        # ä»Kerasæ¨¡å‹åˆ›å»ºè½¬æ¢å™¨
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
        
        # è®¾ç½®é‡åŒ–ä¼˜åŒ–
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        # è®¾ç½®ä»£è¡¨æ€§æ•°æ®é›†ç”¨äºé‡åŒ–æ ¡å‡†
        converter.representative_dataset = representative_data_gen
        
        # å¼ºåˆ¶INT8é‡åŒ–
        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
        
        # è®¾ç½®è¾“å…¥è¾“å‡ºç±»å‹ä¸ºINT8ï¼ˆEdgeTPUè¦æ±‚ï¼‰
        converter.inference_input_type = tf.int8
        converter.inference_output_type = tf.int8
        
        print(f"ğŸ“Š ä½¿ç”¨ä»£è¡¨æ€§æ•°æ®è¿›è¡Œé‡åŒ–æ ¡å‡†...")
        
        # æ‰§è¡Œé‡åŒ–è½¬æ¢
        quantized_tflite_model = converter.convert()
        
        # ä¿å­˜é‡åŒ–æ¨¡å‹
        with open(quantized_path, 'wb') as f:
            f.write(quantized_tflite_model)
        
        print(f"âœ… INT8é‡åŒ–æ¨¡å‹å·²ä¿å­˜: {quantized_path}")
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
        quantized_size = len(quantized_tflite_model) / (1024 * 1024)
        print(f"ğŸ“Š é‡åŒ–æ¨¡å‹å¤§å°: {quantized_size:.2f}MB")
        
        return quantized_path
        
    except Exception as e:
        print(f"âŒ INT8é‡åŒ–å¤±è´¥: {e}")
        print(f"ğŸ’¡ å°è¯•åˆ›å»ºé»˜è®¤é‡åŒ–ç‰ˆæœ¬...")
        
        # å¦‚æœINT8é‡åŒ–å¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤é‡åŒ–ç‰ˆæœ¬
        try:
            converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
            converter.optimizations = [tf.lite.Optimize.DEFAULT]
            fallback_model = converter.convert()
            
            with open(quantized_path, 'wb') as f:
                f.write(fallback_model)
            
            print(f"âœ… é»˜è®¤é‡åŒ–æ¨¡å‹å·²ä¿å­˜: {quantized_path}")
            print(f"âš ï¸  æ³¨æ„: è¿™ä¸æ˜¯INT8é‡åŒ–ï¼ŒEdgeTPUå…¼å®¹æ€§å¯èƒ½æœ‰é™")
            
            return quantized_path
        except Exception as e2:
            print(f"âŒ é»˜è®¤é‡åŒ–ä¹Ÿå¤±è´¥: {e2}")
            return None

def compile_to_edgetpu(quantized_tflite_path, model_name):
    """æ­¥éª¤3: ç¼–è¯‘é‡åŒ–æ¨¡å‹ä¸ºEdgeTPUæ ¼å¼"""
    
    print(f"ğŸš€ æ­¥éª¤3: ç¼–è¯‘ {model_name} ä¸ºEdgeTPU...")
    
    if not os.path.exists(quantized_tflite_path):
        print(f"âŒ é‡åŒ–æ–‡ä»¶ä¸å­˜åœ¨: {quantized_tflite_path}")
        return None
    
    # ç”ŸæˆEdgeTPUæ–‡ä»¶åå’Œæ—¥å¿—æ–‡ä»¶å
    edgetpu_path = quantized_tflite_path.replace('_quantized.tflite', '_edgetpu.tflite')
    log_path = quantized_tflite_path.replace('_quantized.tflite', '_edgetpu.log')
    
    print(f"ğŸ”„ ç¼–è¯‘ {quantized_tflite_path} -> {edgetpu_path}")
    print(f"ï¿½ ç¼–è¯‘æ—¥å¿—å°†ä¿å­˜åˆ°: {log_path}")
    
    try:
        # è¿è¡ŒEdgeTPUç¼–è¯‘å™¨å¹¶ä¿å­˜æ—¥å¿—
        result = subprocess.run([
            'edgetpu_compiler', 
            quantized_tflite_path,
            '-o', '.',
            '--out_dir', '.'
        ], capture_output=True, text=True, timeout=300)
        
        # ä¿å­˜è¯¦ç»†æ—¥å¿—
        log_content = f"EdgeTPUç¼–è¯‘æ—¥å¿— - {model_name}\n"
        log_content += f"="*50 + "\n"
        log_content += f"è¾“å…¥æ–‡ä»¶: {quantized_tflite_path}\n"
        log_content += f"è¾“å‡ºæ–‡ä»¶: {edgetpu_path}\n"
        log_content += f"ç¼–è¯‘æ—¶é—´: {subprocess.time.time() if hasattr(subprocess, 'time') else 'N/A'}\n"
        log_content += f"è¿”å›ç : {result.returncode}\n\n"
        
        if result.stdout:
            log_content += "æ ‡å‡†è¾“å‡º:\n"
            log_content += result.stdout + "\n\n"
        
        if result.stderr:
            log_content += "é”™è¯¯è¾“å‡º:\n"
            log_content += result.stderr + "\n\n"
        
        # å†™å…¥æ—¥å¿—æ–‡ä»¶
        with open(log_path, 'w', encoding='utf-8') as f:
            f.write(log_content)
        
        if result.returncode == 0:
            print(f"âœ… EdgeTPUç¼–è¯‘æˆåŠŸ: {edgetpu_path}")
            print(f"ğŸ“Š ç¼–è¯‘ä¿¡æ¯:")
            
            # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
            if result.stdout:
                for line in result.stdout.split('\n'):
                    if ('Model successfully compiled' in line or 
                        'Ops mapped to Edge TPU' in line or
                        'Compilation succeeded' in line):
                        print(f"   {line}")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if os.path.exists(edgetpu_path):
                size_mb = os.path.getsize(edgetpu_path) / (1024 * 1024)
                print(f"   EdgeTPUæ¨¡å‹å¤§å°: {size_mb:.2f} MB")
            
            print(f"ğŸ“ è¯¦ç»†æ—¥å¿—: {log_path}")
            return edgetpu_path
        else:
            print(f"âŒ EdgeTPUç¼–è¯‘å¤±è´¥")
            print(f"ğŸ“ è¯¦ç»†é”™è¯¯æ—¥å¿—: {log_path}")
            return None
            
    except subprocess.TimeoutExpired:
        print(f"âŒ ç¼–è¯‘è¶…æ—¶: {quantized_tflite_path}")
        return None
    except Exception as e:
        print(f"âŒ ç¼–è¯‘å¼‚å¸¸: {e}")
        return None

def main():
    """ä¸»å‡½æ•° - åˆ›å»ºä¸‰ç§ç»å…¸æ¶æ„çš„EdgeTPUç‰ˆæœ¬"""
    
    print("ğŸ—ï¸  åˆ›å»ºåŸºäºç»å…¸æ¶æ„çš„EdgeTPUæ·±åº¦ä¼°è®¡æ¨¡å‹")
    print("="*60)
    print(f"ğŸ“ ä½¿ç”¨640x480åˆ†è¾¨ç‡ (ä¸æ„ŸçŸ¥ç®¡é“ä¸€è‡´)")
    
    models_created = []
    
    # 1. FastDepth + MobileNetV2
    print("\n1ï¸âƒ£  FastDepth + MobileNetV2 (å•ç›®æ·±åº¦ä¼°è®¡)")
    fastdepth = FastDepthEdgeTPU(input_height=480, input_width=640)
    fastdepth_model = fastdepth.build_fastdepth_model()
    
    print(f"ğŸ“Š FastDepthæ¨¡å‹å‚æ•°: {fastdepth_model.count_params():,}")
    
    # 2. MobileNetV2 ç«‹ä½“æ·±åº¦ä¼°è®¡  
    print("\n2ï¸âƒ£  MobileNetV2 + ç«‹ä½“åŒ¹é…")
    stereo_depth = MobileNetV2StereoDepth(input_height=480, input_width=640)
    stereo_model = stereo_depth.build_stereo_model()
    
    print(f"ğŸ“Š ç«‹ä½“æ·±åº¦æ¨¡å‹å‚æ•°: {stereo_model.count_params():,}")
    
    # 3. MiDaSé£æ ¼çš„MobileNet
    print("\n3ï¸âƒ£  MiDaS + MobileNet (å¤šå°ºåº¦èåˆ)")
    midas_mobilenet = MiDaSMobileNet(input_height=480, input_width=640)
    midas_model = midas_mobilenet.build_midas_mobilenet()
    
    print(f"ğŸ“Š MiDaS-MobileNetå‚æ•°: {midas_model.count_params():,}")
    
    # ä¿å­˜æ¨¡å‹æ¶æ„å›¾
    print(f"\nğŸ“‹ ä¿å­˜æ¨¡å‹æ¶æ„å›¾...")
    try:
        for model, name in [(fastdepth_model, 'FastDepth'), 
                           (stereo_model, 'StereoDepth'), 
                           (midas_model, 'MiDaS')]:
            
            tf.keras.utils.plot_model(
                model, 
                to_file=f'{name.lower()}_architecture.png',
                show_shapes=True,
                show_layer_names=True
            )
            print(f"âœ… {name} æ¶æ„å›¾å·²ä¿å­˜")
            
            models_created.append((model, name))
    except Exception as e:
        print(f"âš ï¸  æ¶æ„å›¾ä¿å­˜å¤±è´¥ (æ­£å¸¸ï¼Œç»§ç»­): {e}")
        models_created = [(fastdepth_model, 'FastDepth'), 
                         (stereo_model, 'StereoDepth'), 
                         (midas_model, 'MiDaS')]
    
    # è½¬æ¢å’Œç¼–è¯‘æµç¨‹
    print(f"\nğŸ”§ å¼€å§‹ä¸‰æ­¥éª¤è½¬æ¢æµç¨‹...")
    print(f"  æ­¥éª¤1: Keras -> TFLite")
    print(f"  æ­¥éª¤2: TFLite -> é‡åŒ–TFLite") 
    print(f"  æ­¥éª¤3: é‡åŒ–TFLite -> EdgeTPU")
    
    # ç”Ÿæˆä»£è¡¨æ€§æ•°æ®é›†ç”¨äºé‡åŒ–
    def representative_data_gen_mono():
        """å•ç›®æ¨¡å‹çš„ä»£è¡¨æ€§æ•°æ®"""
        for i in range(50):  # ç®€åŒ–ä¸º50ä¸ªæ ·æœ¬
            data = np.random.rand(1, 480, 640, 3).astype(np.float32)
            data = data * 0.8 + 0.1  # è°ƒæ•´åˆ°[0.1, 0.9]èŒƒå›´
            yield [data]
    
    def representative_data_gen_stereo():
        """ç«‹ä½“æ¨¡å‹çš„ä»£è¡¨æ€§æ•°æ®"""
        for i in range(50):  # ç®€åŒ–ä¸º50ä¸ªæ ·æœ¬
            left_data = np.random.rand(1, 480, 640, 3).astype(np.float32)
            right_data = np.random.rand(1, 480, 640, 3).astype(np.float32)
            left_data = left_data * 0.8 + 0.1
            right_data = right_data * 0.8 + 0.1
            yield [left_data, right_data]
    
    # å¤„ç†æ¯ä¸ªæ¨¡å‹
    edgetpu_models = []
    
    for model, name in models_created:
        print(f"\nğŸ”„ å¤„ç† {name}...")
        
        try:
            # æ­¥éª¤1: è½¬æ¢ä¸ºTFLite
            tflite_path = convert_to_tflite(model, name)
            
            # æ­¥éª¤2: ç›´æ¥ä»Kerasæ¨¡å‹é‡åŒ–ä¸ºINT8 TFLite
            rep_data_gen = representative_data_gen_stereo if name == 'StereoDepth' else representative_data_gen_mono
            quantized_path = quantize_keras_to_tflite(model, name, rep_data_gen)
            
            # æ­¥éª¤3: ç¼–è¯‘ä¸ºEdgeTPU
            if quantized_path:
                edgetpu_path = compile_to_edgetpu(quantized_path, name)
                
                if edgetpu_path:
                    edgetpu_models.append(edgetpu_path)
                    print(f"âœ… {name} å®Œæ•´æµç¨‹æˆåŠŸ")
                else:
                    print(f"âŒ {name} EdgeTPUç¼–è¯‘å¤±è´¥")
            else:
                print(f"âŒ {name} é‡åŒ–å¤±è´¥")
                
        except Exception as e:
            print(f"âŒ {name} å¤„ç†å¤±è´¥: {e}")
            continue
    
    print(f"\nğŸ¯ æ¨èä½¿ç”¨é¡ºåº:")
    print(f"  1. FastDepth (æœ€ç®€å•ï¼Œè®ºæ–‡éªŒè¯) - å•ç›®æ·±åº¦ä¼°è®¡")
    print(f"  2. MobileNetV2-Stereo (ç«‹ä½“åŒ¹é…ï¼Œæ›´å‡†ç¡®) - ç«‹ä½“æ·±åº¦ä¼°è®¡") 
    print(f"  3. MiDaS-MobileNet (æœ€å…ˆè¿›ï¼Œå¤šå°ºåº¦) - å•ç›®æ·±åº¦ä¼°è®¡")
    
    print(f"\nğŸ å®Œæˆæƒ…å†µ:")
    print(f"  â€¢ æ¨¡å‹åˆ›å»º: {len(models_created)}/3")
    print(f"  â€¢ TFLiteè½¬æ¢: æ£€æŸ¥ *.tflite æ–‡ä»¶")
    print(f"  â€¢ é‡åŒ–TFLite: æ£€æŸ¥ *_quantized.tflite æ–‡ä»¶")
    print(f"  â€¢ EdgeTPUç¼–è¯‘: {len(edgetpu_models)}/3")
    
    print(f"\nğŸ“ åˆ†è¾¨ç‡è¯´æ˜:")
    print(f"  â€¢ è¾“å…¥: 640x480 (ä¸æ„ŸçŸ¥ç®¡é“ä¸€è‡´)")
    print(f"  â€¢ FastDepthè¾“å‡º: 640x480x1 (æ·±åº¦å›¾)")
    print(f"  â€¢ StereoDepthè¾“å‡º: 640x480x1 (è§†å·®å›¾)")
    print(f"  â€¢ MiDaSè¾“å‡º: 640x480x1 (ç›¸å¯¹æ·±åº¦)")
    
    if edgetpu_models:
        print(f"\nâœ… ç¼–è¯‘æˆåŠŸçš„EdgeTPUæ¨¡å‹:")
        for model in edgetpu_models:
            print(f"  â€¢ {model}")
        print(f"\nğŸ“ ç¼–è¯‘æ—¥å¿—æ–‡ä»¶:")
        for model in edgetpu_models:
            log_file = model.replace('_edgetpu.tflite', '_edgetpu.log')
            if os.path.exists(log_file):
                print(f"  â€¢ {log_file}")
    
    print(f"\nğŸ¯ æ‰‹åŠ¨EdgeTPUç¼–è¯‘å‘½ä»¤ï¼ˆå¦‚éœ€è¦ï¼‰:")
    print(f"edgetpu_compiler fastdepth_quantized.tflite")
    print(f"edgetpu_compiler stereodepth_quantized.tflite") 
    print(f"edgetpu_compiler midas_quantized.tflite")
    
    return models_created, edgetpu_models

if __name__ == "__main__":
    models = main()
